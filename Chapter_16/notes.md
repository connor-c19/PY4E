# Building Visualization Apps

- Steps for example application:
  - Gather data from source into raw database, usually through a web crawler
  - Clean and process data into clean, smaller database
  - Visualize/Analyze clean data

`https://www.py4e.com/code3.zip`

- Web crawler, a computer program that browses the World Wide Web in a methodical, automated manner:

  - Retrieve a page
  - Look through the page for links
  - Add the links to a list of "to be retrieved" sites
  - Repeat

- Web crawling policy:

  - Selection policy: which pages to download
  - re-visit policy: when to check for changes to the pages
  - politeness policy: how to avoid overloading websites
  - parallelization policy: how to coordinate distributed web crawlers

- robots.txt: a way for web site to communicate with web crawlers, an informal and voluntary standard

- Page rank: figure out which pages have the most 'best' links

  - Value is determined by how many links are within links on a page

- Search indexing: collects, parses, and stores data to facilitate fast and accurate information retrieval
